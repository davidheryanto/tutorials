{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Build a language detector model\n",
    "\n",
    "The goal of this exercise is to train a linear classifier on text features\n",
    "that represent sequences of up to 3 consecutive characters so as to be\n",
    "recognize natural languages by using the frequencies of short character\n",
    "sequences as 'fingerprints'.\n",
    "\n",
    "\"\"\"\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "# License: Simplified BSD\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "wikipedia_languages_dataset_path = os.path.join(data_path, 'sklearn_text_analytics', 'paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The training data folder must be passed as first argument\n",
    "languages_data_folder = wikipedia_languages_dataset_path\n",
    "dataset = load_files(languages_data_folder)\n",
    "\n",
    "# Split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "Het project begon met een conversatie tussen twee internetvrienden, Larry Sanger, hoofdredacteur van Nupedia en Ben Kovitz, een computerprogrammeur en bèta-wetenschapper, op de avond van 3 januari 2001 in San Diego (Californië). Kovitz had al eerder te maken gehad met een ander soort wikiproject, en toen hij het basisconcept aan Sanger uitlegde, zag deze onmiddellijk dat het wikiformat uitstekend geschikt zou zijn voor het opzetten van een opener, minder formeel project dan Nupedia.\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(type(docs_train))\n",
    "print(docs_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TASK: Build a an vectorizer that splits strings into sequence of 1 to 3\n",
    "# characters instead of word tokens\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer / classifier pipeline using the previous analyzer\n",
    "# the pipeline instance should stored in a variable named clf\n",
    "clf = Pipeline([('vectorizer', vectorizer), ('perceptron', Perceptron(penalty='l2'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='char', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf...n_iter=5, n_jobs=1, penalty='l2', random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Fit the pipeline on the training set\n",
    "clf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       1.00      1.00      1.00        15\n",
      "         de       1.00      1.00      1.00        42\n",
      "         en       1.00      1.00      1.00        71\n",
      "         es       0.98      1.00      0.99        54\n",
      "         fr       1.00      1.00      1.00        53\n",
      "         it       1.00      1.00      1.00        46\n",
      "         ja       1.00      1.00      1.00        34\n",
      "         nl       1.00      1.00      1.00        19\n",
      "         pl       1.00      1.00      1.00        17\n",
      "         pt       1.00      1.00      1.00        48\n",
      "         ru       1.00      0.97      0.99        37\n",
      "\n",
      "avg / total       1.00      1.00      1.00       436\n",
      "\n",
      "[[15  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 71  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 54  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 53  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 34  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 19  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 17  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 48  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0 36]]\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAC4tJREFUeJzt3X2IZXd9x/H3p4lP2xCDFKPWlbtIU2xJwWBLGpFuJYUQ\n",
       "JPWPUhMUQyhCS9VEUJoINQn9x4pihNIWNQkJxki7ikTQ1viwiyVFTLOJazYhrWTIg2QjPiSktJDU\n",
       "b/+YW53ZzOzcPXPunpl+3y+4eO/dk59fjO89Z+49+9tUFZJ6+KWpB5B06hi81IjBS40YvNSIwUuN\n",
       "GLzUyKTBJ7koyYNJ/j3JX0w5y/GS7E3yzST3J/lekvdOPdNmkpyW5HCSL009y/GSnJXkQJIHkhxN\n",
       "cv7UMx0vyTXzf89Hknw2yYt2wEw3JTmW5Mia916W5M4kDyX5apKzTnbdyYJPchrwN8BFwG8AlyV5\n",
       "3VTzbOBZ4H1V9ZvA+cCf77D51roSOArsxJsqPgF8uapeB/wW8MDE86yTZAa8Czivqs4FTgMunXKm\n",
       "uZtZbWOtq4E7q+oc4Ovz1ydlyjP87wD/UVUrVfUs8DngDyecZ52qeqKq7p0/f4bV/6O+atqpni/J\n",
       "q4GLgU8DmXicdZK8FHhTVd0EUFXPVdVTE491vKdZ/c19T5LTgT3A49OOBFX1LeAnx719CXDL/Pkt\n",
       "wFtPdt0pg/9V4NE1rx+bv7fjzM8Crwe+Pe0kG/o48AHgZ1MPsoF9wA+T3JzkniSfSrJn6qHWqqof\n",
       "Ax8DHgF+APy0qr427VSbOruqjs2fHwPOPtkFpgx+J15+Pk+SM4ADwJXzM/2OkeQtwJNVdZgddnaf\n",
       "Ox04D/jbqjoP+E8GXIYuU5LXAlcBM1av4M5I8vZJh1pArd4Tf9INTRn848DeNa/3snqW3zGSvAD4\n",
       "PPCZqvri1PNs4ALgkiQPA7cDb05y68QzrfUY8FhVfWf++gCrvwHsJG8A7qqqH1XVc8AXWP3fdSc6\n",
       "luQVAEleCTx5sgtMGfzdwK8lmSV5IfA24I4J51knSYAbgaNVdcPU82ykqj5YVXurah+rHzR9o6re\n",
       "OfVc/6eqngAeTXLO/K0LgfsnHGkjDwLnJ3nJ/N/5hax+ALoT3QFcPn9+OXDSJ6HTRx3nJFTVc0ne\n",
       "Dfwzq5+M3lhVO+kT3DcC7wC+m+Tw/L1rquqfJpxpKzvxx6T3ALfNf1P/PnDFxPOsU1X3za+K7mb1\n",
       "c5B7gE9OOxUkuR34PeBXkjwKfAj4MPAPSf4EWAH++KTX9Y/HSn14p53UiMFLjRi81IjBS40YvNTI\n",
       "0r6WS+LH/9JEqmrDOy+X+z38pQs0f+Q6OPe6rY/73ALHLM1BYP+E//1bOcjOng+ccQwHWWy+6zf9\n",
       "FS/ppUYMXmpk+uBfvn/qCRYwm3qALcymHmABs6kHWMBs6gG2MNv2CoODH217qrP3D/5HT53Z1ANs\n",
       "YTb1AAuYTT3AAmZTD7CF2bZXGBT8LtieStIGhp7hd/T2VJI2NjT4XbM9laRfGBq8N9VIu9DQG28W\n",
       "257qyHW/eP7y/bvkAzppt1mZP7Y2NPifb0/F6k6fbwMue95Ri9xBJ2mbZqz/BP/QpkcOCn4XbE8l\n",
       "aQOD76Wvqq8AXxlxFklLNv2ddpJOGYOXGjF4qRGDlxoxeKmR5e54M+IuNf+6hL/a7Xdz0n/brrSr\n",
       "eYaXGjF4qRGDlxoxeKkRg5caMXipEYOXGjF4qRGDlxoxeKkRg5caMXipEYOXGjF4qRGDlxoxeKkR\n",
       "g5caMXipEYOXGjF4qZHlbmI5omVsOHkt14+63vVcO+p60tg8w0uNGLzUiMFLjRi81IjBS40MCj7J\n",
       "3iTfTHJ/ku8lee/Yg0ka39Cv5Z4F3ldV9yY5A/i3JHdW1QMjziZpZIPO8FX1RFXdO3/+DPAA8Kox\n",
       "B5M0vm3/DJ9kBrwe+PZ215K0XNu6025+OX8AuHJ+pj/OwTXPZ/OHpHGtzB9bGxx8khcAnwc+U7XZ\n",
       "X96+f+jykhY2Y/3J9NCmRw79lD7AjcDRqrphyBqSTr2hP8O/EXgH8PtJDs8fF404l6QlGHRJX1X/\n",
       "gjftSLuO0UqNGLzUiMFLjRi81IjBS43smj3tlmHsPejqo+PukZf3u0eexuUZXmrE4KVGDF5qxOCl\n",
       "RgxeasTgpUYMXmrE4KVGDF5qxOClRgxeasTgpUYMXmrE4KVGDF5qxOClRgxeasTgpUYMXmqk9Z52\n",
       "Yxt7D7r6+3H3yAPIn7pPXmee4aVGDF5qxOClRgxeasTgpUYMXmpkW8EnOS3J4SRfGmsgScuz3TP8\n",
       "lcBRoEaYRdKSDQ4+yauBi4FPAxltIklLs50z/MeBDwA/G2kWSUs26NbaJG8Bnqyqw0n2b37kwTXP\n",
       "Z/OHpHGtzB9bG3ov/QXAJUkuBl4MnJnk1qp65/rD9g9cXtLiZqw/mR7a9MhBl/RV9cGq2ltV+4BL\n",
       "gW88P3ZJO81Y38P7Kb20C2z7j8dW1SFOdA0hacfwTjupEYOXGjF4qRGDlxoxeKkRN7HcwZax4eQz\n",
       "//1Xo653xov/ctT1tFye4aVGDF5qxOClRgxeasTgpUYMXmrE4KVGDF5qxOClRgxeasTgpUYMXmrE\n",
       "4KVGDF5qxOClRgxeasTgpUYMXmrE4KVG3NOumbH3oPuzOnPU9QD+Lk+PvqZWeYaXGjF4qRGDlxox\n",
       "eKkRg5caGRx8krOSHEjyQJKjSc4fczBJ49vO13KfAL5cVX+U5HTgl0eaSdKSDAo+yUuBN1XV5QBV\n",
       "9Rzw1JiDSRrf0Ev6fcAPk9yc5J4kn0qyZ8zBJI1v6CX96cB5wLur6jtJbgCuBj60/rCDa57P5g9J\n",
       "41qZP7Y2NPjHgMeq6jvz1wdYDf44+wcuL2lxM9afTA9teuSgS/qqegJ4NMk587cuBO4fspakU2c7\n",
       "n9K/B7gtyQuB7wNXjDOSpGUZHHxV3Qf89oizSFoy77STGjF4qRGDlxoxeKkRg5caMXipETex1LYs\n",
       "ZcPJG64bd72rRl5vF/MMLzVi8FIjBi81YvBSIwYvNWLwUiMGLzVi8FIjBi81YvBSIwYvNWLwUiMG\n",
       "LzVi8FIjBi81YvBSIwYvNWLwUiMGLzXinnbaecbeg+79I6/30ZHXO4U8w0uNGLzUiMFLjRi81IjB\n",
       "S40MDj7JNUnuT3IkyWeTvGjMwSSNb1DwSWbAu4Dzqupc4DTg0vHGkrQMQ7+Hfxp4FtiT5H+APcDj\n",
       "o00laSkGneGr6sfAx4BHgB8AP62qr405mKTxDTrDJ3ktcBUwA54C/jHJ26vqtvVHHlzzfDZ/SBrX\n",
       "yvyxtaGX9G8A7qqqHwEk+QJwAXBc8PsHLi9pcTPWn0wPbXrk0E/pHwTOT/KSJAEuBI4OXEvSKTL0\n",
       "Z/j7gFuBu4Hvzt/+5FhDSVqOwX9arqo+AnxkxFkkLZl32kmNGLzUiMFLjRi81IjBS424p53+/xt5\n",
       "D7p66PpR1wPIOdeOvuZGPMNLjRi81IjBS40YvNSIwUuNGLzUiMFLjRi81IjBS40YvNSIwUuNGLzU\n",
       "iMFLjRi81IjBS40YvNSIwUuNGLzUiMFLjRi81IibWI7qzJHXe3rk9TSGZWw4eV3913hrZfNf8wwv\n",
       "NWLwUiMGLzVi8FIjJww+yU1JjiU5sua9lyW5M8lDSb6a5KzljylpDFud4W8GLjruvauBO6vqHODr\n",
       "89eSdoETBl9V3wJ+ctzblwC3zJ/fArx1CXNJWoIhP8OfXVXH5s+PAWePOI+kJdrWh3ZVVUCNNIuk\n",
       "JRtyp92xJK+oqieSvBJ4cvNDD655Pps/JI3p4YOPsHLwkYWOHRL8HcDlwF/P//OLmx+6f8Dykk7G\n",
       "vv2vYd/+1/z89aHr79r02K2+lrsduAv49SSPJrkC+DDwB0keAt48fy1pFzjhGb6qLtvkly5cwiyS\n",
       "lsw77aRGDF5qZAcEvzL1AAtYmXqALaxMPcACVqYeYAErUw9wQg8v+En8iRj8QlamHmALK1MPsICV\n",
       "qQdYwMrUA5zQol+9ncgOCF7SqWLwUiNZvTt2CQsn3nIrTaSqNtzZbmnBS9p5vKSXGjF4qRGDlxox\n",
       "eKkRg5ca+V+mHlkQv8tQBgAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a20b51f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "pl.matshow(cm, cmap=pl.cm.jet)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"This is a language detection test.\" is \"en\"\n",
      "The language of \"Ceci est un test de détection de la langue.\" is \"fr\"\n",
      "The language of \"Dies ist ein Test, um die Sprache zu erkennen.\" is \"de\"\n"
     ]
    }
   ],
   "source": [
    "# Predict the result on some short new sentences:\n",
    "sentences = [\n",
    "    u'This is a language detection test.',\n",
    "    u'Ceci est un test de d\\xe9tection de la langue.',\n",
    "    u'Dies ist ein Test, um die Sprache zu erkennen.',\n",
    "]\n",
    "predicted = clf.predict(sentences)\n",
    "\n",
    "for s, p in zip(sentences, predicted):\n",
    "    print(u'The language of \"%s\" is \"%s\"' % (s, dataset.target_names[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
