{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN Black\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layer min reqs:\n",
    "- subclass `Layer`\n",
    "- implement `get_output_for()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoubleLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return 2 * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If layer changes shape of the data, implement get_output_shape_for() -> tuple of int\n",
    "# e.g. layer that computes sum across trailing axis of its input\n",
    "class SumLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return input.sum(axis=1)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer parameters, should be init in the constructor\n",
    "class DotLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, num_units, W=lasagne.init.Normal(0.01), **kwargs):\n",
    "        super(DotLayer, self).__init__(incoming, **kwargs)\n",
    "        num_inputs = self.input_shape[1]\n",
    "        self.num_units = num_units\n",
    "        self.W = self.add_param(W, (num_inputs, num_units), name='W')  # Create Theano shared var\n",
    "                                                                       # retrieved with Layer.get_params()\n",
    "                                                                       # or in this case self.W\n",
    "    \n",
    "    def get_output_for(self, input, **kwargs):  # kwargs use case: turn on/off dropout at training/testing\n",
    "        return T.dot(input, self.W)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.num_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rough implementation of dropout\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "_srng = RandomStreams()\n",
    "\n",
    "class DropoutLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, p=0.5, **kwargs):\n",
    "        super(DropoutLayer, self).__init__(incoming, **kwargs)\n",
    "        self.p = p\n",
    "    \n",
    "    def get_output_for(self, input, deterministic=False, **kwargs):\n",
    "        if deterministic:\n",
    "            return input\n",
    "        else:\n",
    "            retain_prob = 1 - self.p\n",
    "            return input * _srng.binomial(input.shape, p=retain_prob, dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
